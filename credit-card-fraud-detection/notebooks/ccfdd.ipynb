{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection\n",
    "## Using Unsupervised Anomaly Detection\n",
    "\n",
    "**Author:** Farès HAMDI  \n",
    "**Date:** 2025  \n",
    "\n",
    "---\n",
    "\n",
    "### About this project\n",
    "\n",
    "This notebook explores how **unsupervised learning** can help detect fraudulent credit card transactions. The idea is simple: frauds are rare and unusual, so they should stand out as **anomalies** in the data.\n",
    "\n",
    "We use two classic anomaly detection algorithms:\n",
    "- **Isolation Forest**: isolates anomalies by randomly partitioning the data\n",
    "- **Local Outlier Factor (LOF)**: compares local density of points\n",
    "\n",
    "The `Class` column (0 = legit, 1 = fraud) is only used to **evaluate** how well the algorithms perform. In a real scenario, we often don't have reliable labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "# Import our modules\n",
    "from data_loading import load_data, print_dataset_summary, get_amount_statistics, get_top_correlations\n",
    "from preprocessing import preprocess_pipeline\n",
    "from models import train_all_models\n",
    "from evaluation import evaluate_model, print_evaluation_report, compare_models, save_predictions\n",
    "from visualization import (\n",
    "    setup_plot_style,\n",
    "    plot_eda_overview,\n",
    "    plot_pca_projection,\n",
    "    plot_score_distributions,\n",
    "    plot_precision_recall_curves,\n",
    "    plot_detection_comparison,\n",
    "    plot_results_summary\n",
    ")\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "setup_plot_style()\n",
    "\n",
    "# Output directory for figures\n",
    "FIGURES_DIR = Path.cwd().parent / 'outputs' / 'figures'\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the Data\n",
    "\n",
    "The dataset contains ~284,000 transactions made by European cardholders in September 2013.  \n",
    "Only 492 of them are frauds — that's about **0.17%**. A needle in a haystack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "DATA_PATH = Path.cwd().parent / 'data' / 'creditcard.csv'\n",
    "\n",
    "df = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset summary\n",
    "print_dataset_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First look at the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "\n",
    "Let's explore the data to understand its characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction amount statistics\n",
    "stats = get_amount_statistics(df)\n",
    "\n",
    "print(\"Transaction Amounts:\")\n",
    "print(f\"  Overall - Mean: €{stats['overall']['mean']:.2f}, Median: €{stats['overall']['median']:.2f}\")\n",
    "print(f\"  Legitimate - Mean: €{stats['legitimate']['mean']:.2f}\")\n",
    "print(f\"  Fraudulent - Mean: €{stats['fraudulent']['mean']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top features correlated with fraud\n",
    "correlations = get_top_correlations(df, n=5)\n",
    "\n",
    "print(\"Features most correlated with fraud:\")\n",
    "print(correlations.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA visualizations\n",
    "plot_eda_overview(df, save_path=FIGURES_DIR / '01_eda_overview.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- Extreme class imbalance: ~284k legitimate vs ~500 frauds\n",
    "- Most transactions are small amounts\n",
    "- Transactions spread across 48 hours\n",
    "- Fraudulent transactions tend to have lower amounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "The V1-V28 features are already scaled (from PCA). We need to standardize `Time` and `Amount`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run preprocessing pipeline\n",
    "preprocessed = preprocess_pipeline(df)\n",
    "\n",
    "X = preprocessed['X']\n",
    "X_scaled = preprocessed['X_scaled']\n",
    "y = preprocessed['y']\n",
    "X_2d = preprocessed['X_2d']\n",
    "pca = preprocessed['pca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 2D projection\n",
    "plot_pca_projection(X_2d, y, pca, save_path=FIGURES_DIR / '02_pca_projection.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice:** Frauds (red) don't form a clear cluster. They're scattered around, which makes detection tricky."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Anomaly Detection Models\n",
    "\n",
    "We'll train two unsupervised models:\n",
    "1. **Isolation Forest**: Isolates anomalies using random partitioning\n",
    "2. **Local Outlier Factor**: Compares local density to neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models\n",
    "model_results = train_all_models(X_scaled, y)\n",
    "\n",
    "# Extract results\n",
    "iso_results = model_results['isolation_forest']\n",
    "lof_results = model_results['lof']\n",
    "\n",
    "pred_iso = iso_results['predictions']\n",
    "pred_lof = lof_results['predictions']\n",
    "scores_iso = iso_results['scores']\n",
    "scores_lof = lof_results['scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation\n",
    "\n",
    "Now let's evaluate how well each model performs at detecting actual frauds.\n",
    "\n",
    "**Important metrics for imbalanced data:**\n",
    "- **Recall**: Of all actual frauds, how many did we catch?\n",
    "- **Precision**: Of all predicted anomalies, how many are actual frauds?\n",
    "- **Average Precision**: Area under the precision-recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Isolation Forest\n",
    "results_iso = evaluate_model(y, pred_iso, scores_iso, \"Isolation Forest\")\n",
    "print_evaluation_report(results_iso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate LOF\n",
    "results_lof = evaluate_model(y, pred_lof, scores_lof, \"Local Outlier Factor\")\n",
    "print_evaluation_report(results_lof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "compare_models([results_iso, results_lof])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score distributions\n",
    "plot_score_distributions(y, scores_iso, scores_lof, \n",
    "                         save_path=FIGURES_DIR / '03_score_distributions.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall curves\n",
    "plot_precision_recall_curves(y, scores_iso, scores_lof, results_iso, results_lof,\n",
    "                             save_path=FIGURES_DIR / '04_precision_recall.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection comparison in 2D\n",
    "plot_detection_comparison(X_2d, y, pred_iso, pred_lof,\n",
    "                          save_path=FIGURES_DIR / '05_detection_comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results summary\n",
    "plot_results_summary(results_iso, results_lof,\n",
    "                     save_path=FIGURES_DIR / '06_results_summary.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to CSV\n",
    "save_predictions(\n",
    "    y,\n",
    "    {'isolation_forest': pred_iso, 'lof': pred_lof},\n",
    "    {'isolation_forest': scores_iso, 'lof': scores_lof},\n",
    "    filepath=Path.cwd().parent / 'outputs' / 'predictions.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "Both algorithms face the classic **precision-recall tradeoff**:\n",
    "- To catch more frauds (higher recall), we inevitably flag more legitimate transactions as suspicious (more false positives)\n",
    "- Both models achieve similar performance (~70% recall, ~7% precision)\n",
    "\n",
    "### Challenges\n",
    "\n",
    "1. **Extreme class imbalance** (0.17% frauds)\n",
    "2. **Frauds don't cluster together** — they're spread throughout the feature space\n",
    "3. **Anonymized features** limit interpretability\n",
    "\n",
    "### Possible Improvements\n",
    "\n",
    "- **Ensemble methods**: Combine multiple algorithms\n",
    "- **Threshold tuning**: Adjust based on business costs\n",
    "- **Feature engineering**: Create new features from existing ones\n",
    "- **Supervised learning**: If reliable labels are available\n",
    "- **Temporal validation**: Train on past data, test on future data\n",
    "\n",
    "### Production Considerations\n",
    "\n",
    "In production, you'd need to:\n",
    "- Set the threshold based on the cost of missing a fraud vs. blocking a legitimate transaction\n",
    "- Continuously monitor and retrain as fraud patterns evolve\n",
    "- Implement real-time scoring capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of generated files\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"GENERATED FILES\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nFigures (in outputs/figures/):\")\n",
    "print(\"  - 01_eda_overview.png\")\n",
    "print(\"  - 02_pca_projection.png\")\n",
    "print(\"  - 03_score_distributions.png\")\n",
    "print(\"  - 04_precision_recall.png\")\n",
    "print(\"  - 05_detection_comparison.png\")\n",
    "print(\"  - 06_results_summary.png\")\n",
    "print(\"\\nData (in outputs/):\")\n",
    "print(\"  - predictions.csv\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Done!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
